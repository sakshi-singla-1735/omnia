- name: {{ functional_group_name }}
  description: "{{ functional_group_name }}"
  file:
    encoding: plain
    content: |
      ## template: jinja
      #cloud-config

      merge_how:
      - name: list
        settings: [append]
      - name: dict
        settings: [no_replace, recurse_list]

      users:
        - name: root
          ssh_authorized_keys: "{{ read_ssh_key.stdout }}"
          lock_passwd: false
          hashed_passwd: "{{ hashed_password_output.stdout }}"
      disable_root: false

      write_files:
        - path: /usr/local/bin/doca-install.sh
          owner: root:root
          permissions: '{{ file_mode_755 }}'
          content: |
            {{ lookup('template', 'templates/doca-ofed/doca-install.sh.j2') | indent(12) }}

        - path: /usr/local/bin/configure-ib-network.sh
          owner: root:root
          permissions: '{{ file_mode_755 }}'
          content: |
            {{ lookup('template', 'templates/doca-ofed/configure-ib-network.sh.j2') | indent(12) }}

        - path: /usr/local/bin/set-ssh.sh
          permissions: '0755'
          content: |
            #!/bin/bash
            timedatectl set-timezone {{ hostvars['oim']['oim_timezone'] }}
            sed -i 's/^#PermitRootLogin.*/PermitRootLogin yes/' /etc/ssh/sshd_config
            sed -i 's/^#PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config
            sed -i 's/^PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config.d/50-cloud-init.conf
            systemctl restart sshd
            default_count=$(ip route | grep -c "^default")
            if [ "$default_count" -le 1 ]; then
                echo "Only one or no default route found. No action needed."
            else
                private_nic=$(ip route | grep "^default via {{ hostvars['localhost']['admin_nic_ip'] }}" | awk '{print $5}')
                # Get all default routes
                ip route | grep '^default' | while read -r line; do
                    nmcli con del "Wired Connection"
                    # Extract NIC name
                    nic=$(echo "$line" | awk '{print $5}')

                    # Add the default route to the connection
                    if [ -n "$nic" ]; then
                        echo "Adding nmcli device $nic"
                        nmcli con add type ethernet ifname "$nic" con-name "$nic" ipv4.method auto
                        if [ "$nic" = "$private_nic" ]; then
                          nmcli con modify "$nic" ipv4.never-default yes
                          nmcli con delete "cloud-init $nic"
                        fi
                        nmcli con up "$nic"
                    else
                        echo "No connection found for device $nic"
                    fi
                done
            fi

        - path: /root/.ssh/config
          permissions: '0600'
          content: |
            Host {{ k8s_control_ssh_patterns }}
                IdentityFile {{ k8s_client_mount_path }}/ssh/oim_rsa
                IdentitiesOnly yes

        - path: /etc/modules-load.d/k8s.conf
          content: |
            br_netfilter
            overlay
            nf_conntrack
            vxlan
          permissions: '0644'
        - path: /etc/sysctl.d/k8s.conf
          content: |
            net.bridge.bridge-nf-call-iptables=1
            net.bridge.bridge-nf-call-ip6tables=1
            net.ipv4.ip_forward=1
            vm.overcommit_memory=1
            kernel.panic=10
          permissions: '0644'
        - path: /etc/fstab
          content: |
            {{ k8s_nfs_server_ip }}:{{ k8s_server_share_path }}   {{ k8s_client_mount_path }}        nfs    noatime,nolock     0 0
            {{ k8s_nfs_server_ip }}:{{ k8s_server_share_path }}/{% raw %}{{ ds.meta_data.instance_data.local_ipv4 }}{% endraw %}/kubelet   /var/lib/kubelet     nfs noatime,nolock 0 0
            {{ k8s_nfs_server_ip }}:{{ k8s_server_share_path }}/{% raw %}{{ ds.meta_data.instance_data.local_ipv4 }}{% endraw %}/kubernetes   /etc/kubernetes      nfs noatime,nolock 0 0
            {{ k8s_nfs_server_ip }}:{{ k8s_server_share_path }}/{% raw %}{{ ds.meta_data.instance_data.local_ipv4 }}{% endraw %}/pod-logs   /var/log/pods      nfs noatime,nolock 0 0
            {{ k8s_nfs_server_ip }}:{{ k8s_server_share_path }}/packages   /var/lib/packages        nfs    noatime,nolock     0 0
            tmpfs   /tmp/crio-storage   tmpfs   size={{ k8s_crio_storage_size }},noatime,nodev,nosuid   0 0
          permissions: '0644'
        - path: /etc/containers/storage.conf
          content: |
            [storage]
            driver = "overlay"
            runroot = "/var/run/containers/storage"
            graphroot = "/tmp/crio-storage"
            [storage.options.overlay]
            mount_program = "/usr/bin/fuse-overlayfs"
          permissions: '0644'
        - path: /tmp/crio.conf
          permissions: '0644'
          content: |
            unqualified-search-registries = ["{{ pulp_mirror }}"]
            [[registry]]
            prefix = "docker.io"
            location = "registry-1.docker.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "ghcr.io"
            location = "ghcr.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "quay.io"
            location = "quay.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "registry.k8s.io"
            location = "registry.k8s.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "nvcr.io"
            location = "nvcr.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "public.ecr.aws"
            location = "public.ecr.aws"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "gcr.io"
            location = "gcr.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"

      runcmd:
        - /usr/local/bin/set-ssh.sh
        - "systemctl enable chronyd"
        - "systemctl restart chronyd"
        - "chronyc sources"
        - "chronyc -a makestep"
        - sudo swapoff -a
        - sudo sed -i '/ swap / s/^/#/' /etc/fstab
        - sudo setenforce 0 || true
        - sudo sed -i 's/^SELINUX=enforcing/SELINUX=permissive/' /etc/selinux/config

         # Enable and start firewalld
        - systemctl enable firewalld
        - systemctl start firewalld

        # Open required ports for kube node
        - firewall-cmd --permanent --add-port=22/tcp
        - firewall-cmd --permanent --add-port=10250/tcp
        - firewall-cmd --permanent --add-port=30000-32767/tcp
        - firewall-cmd --permanent --add-port=179/tcp
        - firewall-cmd --permanent --add-port=4789/udp
        - firewall-cmd --permanent --add-port=5473/tcp
        - firewall-cmd --permanent --add-port=51820/udp
        - firewall-cmd --permanent --add-port=51821/udp
        - firewall-cmd --permanent --add-port=9100/tcp
        - firewall-cmd --permanent --add-port=7472/tcp
        - firewall-cmd --permanent --add-port=7472/udp
        - firewall-cmd --permanent --add-port=7946/tcp
        - firewall-cmd --permanent --add-port=7946/udp
        - firewall-cmd --permanent --add-port=9090/tcp
        - firewall-cmd --permanent --add-port=8080/tcp

        # Enable services
        - firewall-cmd --permanent --add-service=http
        - firewall-cmd --permanent --add-service=https

        # Add Kubernetes pod/service CIDRs (replace with your actual values)
        - firewall-cmd --permanent --zone=trusted --add-source={{ k8s_service_addresses }}
        - firewall-cmd --permanent --zone=trusted --add-source={{ k8s_pod_network_cidr }}

        # Set default zone to trusted
        - firewall-cmd --set-default-zone=trusted

        # Reload rules
        - firewall-cmd --reload

        - sudo modprobe br_netfilter || true
        - sudo modprobe overlay || true
        - sudo modprobe nf_conntrack || true
        - sudo modprobe vxlan || true
        - sysctl --system
        - mkdir -p /tmp/crio-storage {{ k8s_client_mount_path }} /var/lib/kubelet /etc/kubernetes /var/log/pods /var/lib/packages
        - |
          tmpfile=$(mktemp)

          # Extract the first 'search' line only (ignore duplicates)
          search_line=$(grep '^search' /etc/resolv.conf | head -n1)
          [ -n "$search_line" ] && echo "$search_line" > "$tmpfile"

          # Add your new nameserver entries
          {% for ns in dns %}
          echo "nameserver {{ ns }}" >> "$tmpfile"
          {% endfor %}

          # Add remaining lines except search and empty lines
          grep -v '^search' /etc/resolv.conf | grep -v '^$' >> "$tmpfile"

          # Remove duplicate lines
          awk '!seen[$0]++' "$tmpfile" > /etc/resolv.conf
        - |
          if command -v chattr >/dev/null 2>&1; then
            chattr +i /etc/resolv.conf || true
          fi
        - systemctl restart rpcbind
        - mount -a
        - cp {{ k8s_client_mount_path }}/pulp_webserver.crt /etc/pki/ca-trust/source/anchors
        - update-ca-trust extract
        - sed -i 's/^gpgcheck=1/gpgcheck=0/' /etc/dnf/dnf.conf
        - bash /usr/local/bin/doca-install.sh && bash /usr/local/bin/configure-ib-network.sh
        - systemctl start crio.service
        - systemctl enable crio.service
        - sudo systemctl enable --now kubelet
        - mv /tmp/crio.conf /etc/containers/registries.conf.d/crio.conf
        - systemctl daemon-reload
        - systemctl restart crio
        - kubeadm config images pull --kubernetes-version={{ service_k8s_version }}
{% set role_name = 'service_kube_node' %}
{% include 'pull_additional_images.yaml.j2' %}
        - |
          set -e
          MARKER="/etc/kubernetes/.cluster_initialized"
          export KUBECONFIG="/etc/kubernetes/admin.conf"
          if [ ! -f "$MARKER" ]; then
            # Join Kubernetes cluster
            echo "Initial boot - initializing and setting up service_kube_node_x86_64"
            rm -rf /var/lib/kubelet/* /etc/kubernetes/*
            rm -rf /var/lib/kubelet/.* /etc/kubernetes/.*
            K8S_CLIENT_MOUNT_PATH="{{ k8s_client_mount_path }}"
            NODE_NAME="{% raw %}{{ ds.meta_data.instance_data.local_ipv4 }}{% endraw %}"
            KUBE_VIP="{{ kube_vip }}"
            JOIN_CMD_FILE="${K8S_CLIENT_MOUNT_PATH}/worker-join-command.sh"
            echo "----------------------------------------------------------------------"
            echo "Waiting for the service_kube_control_plane_first_x86_64 to be initialized."
            echo "This node will automatically join the cluster once it is ready."
            echo "Looking for cluster join command at: $JOIN_CMD_FILE"
            echo "----------------------------------------------------------------------"
            while [ ! -f "$JOIN_CMD_FILE" ]; do
              echo "service_kube_control_plane_first_x86_64 is not ready yet. Waiting for $JOIN_CMD_FILE to be created. Retrying in 10 seconds..."
              sleep 10
            done
            echo "Join command file detected: $JOIN_CMD_FILE"
            echo "Checking if kube-vip (${KUBE_VIP}) is reachable..."
            # Keep pinging kube-vip until it is reachable
            while ! ping -c 1 -W 2 "$KUBE_VIP" >/dev/null 2>&1; do
              echo "kube-vip (${KUBE_VIP}) not reachable. Retrying in 10 seconds..."
              sleep 10
            done
            echo "kube-vip (${KUBE_VIP}) is reachable. Joining this service_kube_node_x86_64 to the cluster now."
            JOIN_CMD="$(cat "$JOIN_CMD_FILE") --node-name ${NODE_NAME}"
            echo "Executing: $JOIN_CMD"
            eval $JOIN_CMD
            sleep 30
            echo "Updating the kubelet arguments."
            sed -i 's/^shutdownGracePeriod:.*/shutdownGracePeriod: 30s/' /var/lib/kubelet/config.yaml
            sed -i 's/^shutdownGracePeriodCriticalPods:.*/shutdownGracePeriodCriticalPods: 10s/' /var/lib/kubelet/config.yaml
            systemctl daemon-reload
            systemctl restart kubelet
            systemctl restart nfs-client.target
            if [ -f /etc/kubernetes/kubelet.conf ]; then
              cp /etc/kubernetes/kubelet.conf /etc/kubernetes/kubelet.conf.bak
              sed -i "s#server: https://[^:]*:6443#server: https://{{ kube_vip }}:6443#" /etc/kubernetes/kubelet.conf
              systemctl restart kubelet
            else
              echo "WARNING: /etc/kubernetes/kubelet.conf not found. Kubelet may not be initialized yet."
            fi
            
            #update the kubelet config.yaml
            CONFIG_FILE="/var/lib/kubelet/config.yaml"

            # Update or add the parameters
            sed -i 's|^nodeStatusUpdateFrequency:.*|nodeStatusUpdateFrequency: 5s|' $CONFIG_FILE
            sed -i 's|^nodeStatusReportFrequency:.*|nodeStatusReportFrequency: 10s|' $CONFIG_FILE
            sed -i 's|^syncFrequency:.*|syncFrequency: 10s|' $CONFIG_FILE

            # If a key is missing, append it
            grep -q "^nodeStatusUpdateFrequency:" $CONFIG_FILE || echo "nodeStatusUpdateFrequency: 5s" >> $CONFIG_FILE
            grep -q "^nodeStatusReportFrequency:" $CONFIG_FILE || echo "nodeStatusReportFrequency: 10s" >> $CONFIG_FILE
            grep -q "^syncFrequency:" $CONFIG_FILE || echo "syncFrequency: 10s" >> $CONFIG_FILE

            # Restart kubelet to apply changes
            systemctl restart kubelet
            # Mark initialization complete so all of above is skipped on reboot!
            touch "$MARKER"
            echo "Cloud-Init has completed successfully."

          else
            # SUBSEQUENT BOOT - SKIP JOIN
            echo "service_kube_node_x86_64 is already part of cluster."
            echo "Cluster already initialized. Performing node reboot procedures."
            # CRI and kubelet already enabled above
            systemctl status kubelet
            echo "Cloud-Init finished successfully after the reboot."
          fi
