- name: {{ functional_group_name }}
  description: "{{ functional_group_name }}"
  file:
    encoding: plain
    content: |
      ## template: jinja
      #cloud-config

      merge_how:
      - name: list
        settings: [append]
      - name: dict
        settings: [no_replace, recurse_list]

      users:
        - name: root
          ssh_authorized_keys: "{{ read_ssh_key.stdout }}"
          lock_passwd: false
          hashed_passwd: "{{ hashed_password_output.stdout }}"
      disable_root: false

      write_files:
        - path: /usr/local/bin/doca-install.sh
          owner: root:root
          permissions: '{{ file_mode_755 }}'
          content: |
            {{ lookup('template', 'templates/doca-ofed/doca-install.sh.j2') | indent(12) }}

        - path: /usr/local/bin/configure-ib-network.sh
          owner: root:root
          permissions: '{{ file_mode_755 }}'
          content: |
            {{ lookup('template', 'templates/doca-ofed/configure-ib-network.sh.j2') | indent(12) }}

        - path: /usr/local/bin/set-ssh.sh
          permissions: '0755'
          content: |
            #!/bin/bash
            timedatectl set-timezone {{ hostvars['oim']['oim_timezone'] }}
            sed -i 's/^#PermitRootLogin.*/PermitRootLogin yes/' /etc/ssh/sshd_config
            sed -i 's/^#PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config
            sed -i 's/^PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config.d/50-cloud-init.conf
            systemctl restart sshd
            default_count=$(ip route | grep -c "^default")
            if [ "$default_count" -le 1 ]; then
                echo "Only one or no default route found. No action needed."
            else
                private_nic=$(ip route | grep "^default via {{ hostvars['localhost']['admin_nic_ip'] }}" | awk '{print $5}')
                # Get all default routes
                ip route | grep '^default' | while read -r line; do
                    nmcli con del "Wired Connection"
                    # Extract NIC name
                    nic=$(echo "$line" | awk '{print $5}')

                    # Add the default route to the connection
                    if [ -n "$nic" ]; then
                        echo "Adding nmcli device $nic"
                        nmcli con add type ethernet ifname "$nic" con-name "$nic" ipv4.method auto
                        if [ "$nic" = "$private_nic" ]; then
                          nmcli con modify "$nic" ipv4.never-default yes
                          nmcli con delete "cloud-init $nic"
                        fi
                        nmcli con up "$nic"
                    else
                        echo "No connection found for device $nic"
                    fi
                done
            fi

        - path: /root/.ssh/config
          permissions: '0600'
          content: |
            Host {{ k8s_control_ssh_patterns }}
                IdentityFile {{ k8s_client_mount_path }}/ssh/oim_rsa
                IdentitiesOnly yes

        - path: /etc/modules-load.d/k8s.conf
          content: |
            br_netfilter
            overlay
            nf_conntrack
            vxlan
          permissions: '0644'
        - path: /etc/sysctl.d/k8s.conf
          content: |
            net.bridge.bridge-nf-call-iptables=1
            net.bridge.bridge-nf-call-ip6tables=1
            net.ipv4.ip_forward=1
            vm.overcommit_memory=1
            kernel.panic=10
          permissions: '0644'
        - path: /etc/fstab
          content: |
            {{ k8s_nfs_server_ip }}:{{ k8s_server_share_path }}   {{ k8s_client_mount_path }}        nfs    noatime,nolock     0 0
            {{ k8s_nfs_server_ip }}:{{ k8s_server_share_path }}/{% raw %}{{ ds.meta_data.instance_data.local_ipv4 }}{% endraw %}/etcd      /var/lib/etcd        nfs noatime,nolock 0 0
            {{ k8s_nfs_server_ip }}:{{ k8s_server_share_path }}/{% raw %}{{ ds.meta_data.instance_data.local_ipv4 }}{% endraw %}/kubelet   /var/lib/kubelet     nfs noatime,nolock 0 0
            {{ k8s_nfs_server_ip }}:{{ k8s_server_share_path }}/{% raw %}{{ ds.meta_data.instance_data.local_ipv4 }}{% endraw %}/kubernetes   /etc/kubernetes      nfs noatime,nolock 0 0
            {{ k8s_nfs_server_ip }}:{{ k8s_server_share_path }}/{% raw %}{{ ds.meta_data.instance_data.local_ipv4 }}{% endraw %}/pod-logs   /var/log/pods      nfs noatime,nolock 0 0
            {{ k8s_nfs_server_ip }}:{{ k8s_server_share_path }}/packages   /var/lib/packages        nfs    noatime,nolock     0 0
            tmpfs   /tmp/crio-storage   tmpfs   size={{ k8s_crio_storage_size }},noatime,nodev,nosuid   0 0
          permissions: '0644'
        - path: /etc/containers/storage.conf
          content: |
            [storage]
            driver = "overlay"
            runroot = "/var/run/containers/storage"
            graphroot = "/tmp/crio-storage"
            [storage.options.overlay]
            mount_program = "/usr/bin/fuse-overlayfs"
          permissions: '0644'
        - path: /tmp/crio.conf
          permissions: '0644'
          content: |
            unqualified-search-registries = ["{{ pulp_mirror }}"]
            [[registry]]
            prefix = "docker.io"
            location = "registry-1.docker.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "ghcr.io"
            location = "ghcr.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "quay.io"
            location = "quay.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "registry.k8s.io"
            location = "registry.k8s.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "nvcr.io"
            location = "nvcr.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "public.ecr.aws"
            location = "public.ecr.aws"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
            [[registry]]
            prefix = "gcr.io"
            location = "gcr.io"
            [[registry.mirror]]
            location = "{{ pulp_mirror }}"
        - path: /tmp/kube-vip.yaml
          owner: root:root
          permissions: '0644'
          content: |
            apiVersion: v1
            kind: Pod
            metadata:
              creationTimestamp: null
              name: kube-vip
              namespace: kube-system
              uid: kube-vip-pod
            spec:
              containers:
                - args:
                    - manager
                  env:
                    - name: vip_arp
                      value: "true"
                    - name: port
                      value: "6443"
                    - name: vip_nodename
                      valueFrom:
                        fieldRef:
                          fieldPath: spec.nodeName
                    - name: vip_interface
                      value: vip_interface
                    - name: vip_cidr
                      value: "{{ admin_netmask_bits }}"
                    - name: dns_mode
                      value: first
                    - name: cp_enable
                      value: "true"
                    - name: cp_namespace
                      value: kube-system
                    - name: svc_enable
                      value: "true"
                    - name: svc_leasename
                      value: plndr-svcs-lock
                    - name: vip_leaderelection
                      value: "true"
                    - name: vip_leasename
                      value: plndr-cp-lock
                    - name: vip_leaseduration
                      value: "5"
                    - name: vip_renewdeadline
                      value: "3"
                    - name: vip_retryperiod
                      value: "1"
                    - name: vip_address
                      value: {{ kube_vip }}
                    - name: prometheus_server
                      value: :2112
                  image: ghcr.io/kube-vip/kube-vip:v0.8.9
                  imagePullPolicy: IfNotPresent
                  name: kube-vip
                  resources: {}
                  securityContext:
                    capabilities:
                      add:
                        - NET_ADMIN
                        - NET_RAW
                  volumeMounts:
                    - mountPath: /etc/kubernetes/admin.conf
                      name: kubeconfig
              hostAliases:
                - hostnames:
                    - kubernetes
                  ip: 127.0.0.1
              hostNetwork: true
              dnsPolicy: ClusterFirstWithHostNet
              volumes:
                - hostPath:
                    path: /etc/kubernetes/admin.conf
                  name: kubeconfig
            status: {}

        - path: /usr/local/bin/install-helm.sh
          permissions: '0755'
          content: |
            #!/bin/bash
            set -e
            HELM_VERSION="v3.19.0"
            ARCH="amd64"
            cp {{ k8s_client_mount_path }}/helm/linux-${ARCH}/helm /usr/local/bin/helm
            chmod +x /usr/local/bin/helm

            # Optional: Set up bash completion
            /usr/local/bin/helm completion bash > /etc/bash_completion.d/helm.sh
            chmod 0755 /etc/bash_completion.d/helm.sh

      runcmd:
        - /usr/local/bin/set-ssh.sh
        - "systemctl enable chronyd"
        - "systemctl restart chronyd"
        - "chronyc sources"
        - "chronyc -a makestep"
        - sudo swapoff -a
        - sudo sed -i '/ swap / s/^/#/' /etc/fstab
        - sudo setenforce 0 || true
        - sudo sed -i 's/^SELINUX=enforcing/SELINUX=permissive/' /etc/selinux/config

        # Enable and start firewalld
        - systemctl enable firewalld
        - systemctl start firewalld

        # Open essential ports
        - firewall-cmd --permanent --add-port=22/tcp
        - firewall-cmd --permanent --add-port=6443/tcp
        - firewall-cmd --permanent --add-port=2379-2380/tcp
        - firewall-cmd --permanent --add-port=10250/tcp
        - firewall-cmd --permanent --add-port=10251/tcp
        - firewall-cmd --permanent --add-port=10252/tcp
        - firewall-cmd --permanent --add-port=10257/tcp
        - firewall-cmd --permanent --add-port=10259/tcp

        # CNI-related ports if running workloads on control plane (NodePort, CNI, etc.)
        - firewall-cmd --permanent --add-port=30000-32767/tcp
        - firewall-cmd --permanent --add-port=179/tcp
        - firewall-cmd --permanent --add-port=4789/udp
        - firewall-cmd --permanent --add-port=5473/tcp
        - firewall-cmd --permanent --add-port=51820/udp
        - firewall-cmd --permanent --add-port=51821/udp
        - firewall-cmd --permanent --add-port=9100/tcp
        - firewall-cmd --permanent --add-port=7472/tcp
        - firewall-cmd --permanent --add-port=7472/udp
        - firewall-cmd --permanent --add-port=7946/tcp
        - firewall-cmd --permanent --add-port=7946/udp
        - firewall-cmd --permanent --add-port=9090/tcp
        - firewall-cmd --permanent --add-port=8080/tcp
        
        # Enable services
        - firewall-cmd --permanent --add-service=http
        - firewall-cmd --permanent --add-service=https

        # Add pod/service networks
        - firewall-cmd --permanent --zone=trusted --add-source={{ k8s_service_addresses }}
        - firewall-cmd --permanent --zone=trusted --add-source={{ k8s_pod_network_cidr }}
        
        # Set default zone to trusted
        - firewall-cmd --set-default-zone=trusted
        
        # Reload the firewall rules
        - firewall-cmd --reload

        - sudo modprobe br_netfilter || true
        - sudo modprobe overlay || true
        - sudo modprobe nf_conntrack || true
        - sudo modprobe vxlan || true
        - sysctl --system
        - mkdir -p /tmp/crio-storage {{ k8s_client_mount_path }} /var/lib/etcd  /var/lib/kubelet /etc/kubernetes /var/log/pods /var/lib/packages
        - |
          tmpfile=$(mktemp)

          # Extract the first 'search' line only (ignore duplicates)
          search_line=$(grep '^search' /etc/resolv.conf | head -n1)
          [ -n "$search_line" ] && echo "$search_line" > "$tmpfile"

          # Add your new nameserver entries
          {% for ns in dns %}
          echo "nameserver {{ ns }}" >> "$tmpfile"
          {% endfor %}

          # Add remaining lines except search and empty lines
          grep -v '^search' /etc/resolv.conf | grep -v '^$' >> "$tmpfile"

          # Remove duplicate lines
          awk '!seen[$0]++' "$tmpfile" > /etc/resolv.conf
        - |
          if command -v chattr >/dev/null 2>&1; then
            chattr +i /etc/resolv.conf || true
          fi
        - mount -a
        - cp {{ k8s_client_mount_path }}/pulp_webserver.crt /etc/pki/ca-trust/source/anchors
        - update-ca-trust extract
        - sed -i 's/^gpgcheck=1/gpgcheck=0/' /etc/dnf/dnf.conf
        - bash /usr/local/bin/doca-install.sh && bash /usr/local/bin/configure-ib-network.sh
        - systemctl start crio.service
        - systemctl enable crio.service
        - sudo systemctl enable --now kubelet
        - mv /tmp/crio.conf /etc/containers/registries.conf.d/crio.conf
        - systemctl daemon-reload
        - systemctl restart crio
        - kubeadm config images pull --kubernetes-version={{ service_k8s_version }}
{% set role_name = 'service_kube_control_plane' %}
{% include 'pull_additional_images.yaml.j2' %}
        - echo "Installing helm"
        - /usr/local/bin/install-helm.sh

        - |
          echo "Installing Necessary Python pip packages"
          python3 -m ensurepip

          PACKAGES=({% for pkg in k8s_pip_packages %}"{{ pkg }}"{% if not loop.last %} {% endif %}{% endfor %})

          for pkg in "${PACKAGES[@]}"; do
              echo "Installing $pkg from offline repo..."
              pip3 install "$pkg" \
                    --find-links="{{ offline_pip_module_path }}/${pkg}/" \
                    --trusted-host "{{ pulp_server_ip }}" \
                    --no-index
          done
          MARKER="/etc/kubernetes/.cluster_initialized"
          export KUBECONFIG="/etc/kubernetes/admin.conf"
          set -e
          if [ ! -f "$MARKER" ]; then
            # Join Kubernetes cluster
            echo "Initial boot - initializing and setting up service_kube_control_plane_x86_64"
            rm -rf /var/lib/etcd/*  /var/lib/kubelet/* /etc/kubernetes/*
            rm -rf /var/lib/etcd/.*  /var/lib/kubelet/.* /etc/kubernetes/.*
            K8S_CLIENT_MOUNT_PATH="{{ k8s_client_mount_path }}"
            NODE_NAME="{% raw %}{{ ds.meta_data.instance_data.local_ipv4 }}{% endraw %}"
            KUBE_VIP="{{ kube_vip }}"
            KUBE_PORT="6443"
            JOIN_CMD_FILE="${K8S_CLIENT_MOUNT_PATH}/control-plane-join-command.sh"

            echo "----------------------------------------------------------------------"
            echo "Waiting for the service_kube_control_plane_first_x86_64 to be initialized."
            echo "This node will automatically join the cluster once it is ready."
            echo "Looking for cluster join command at: $JOIN_CMD_FILE"
            echo "----------------------------------------------------------------------"
            while [ ! -f "$JOIN_CMD_FILE" ]; do
              echo "service_kube_control_plane_first_x86_64 is not ready yet. Waiting for $JOIN_CMD_FILE to be created. Retrying in 10 seconds..."
              sleep 10
            done
            echo "Join command file detected: $JOIN_CMD_FILE"

            echo "Checking if kube-vip (${KUBE_VIP}) is reachable..."
            # Keep pinging kube-vip until it is reachable
            while ! ping -c 1 -W 2 "$KUBE_VIP" >/dev/null 2>&1; do
              echo "kube-vip (${KUBE_VIP}) not reachable. Retrying in 10 seconds..."
              sleep 10
            done
            echo "kube-vip (${KUBE_VIP}) is reachable. Joining this service_kube_control_plane_x86_64 to the cluster now."
            JOIN_CMD="$(cat "$JOIN_CMD_FILE") --node-name ${NODE_NAME} --apiserver-advertise-address ${NODE_NAME}"
            echo "Executing: $JOIN_CMD"
            eval $JOIN_CMD
            mkdir -p /root/.kube
            cp -f /etc/kubernetes/admin.conf /root/.kube/config
            chown root:root /root/.kube/config

            NODE_IP="{% raw %}{{ ds.meta_data.instance_data.local_ipv4 }}{% endraw %}"
            VIP_IFACE=$(ip -o addr show | awk -v ip="$NODE_IP" '$4 ~ ip {print $2}')
            sed -i "s/value: vip_interface/value: ${VIP_IFACE}/" /tmp/kube-vip.yaml
            cp /tmp/kube-vip.yaml /etc/kubernetes/manifests/kube-vip.yaml
        
            if [ -f /etc/kubernetes/kubelet.conf ]; then
              cp /etc/kubernetes/kubelet.conf /etc/kubernetes/kubelet.conf.bak
              sed -i "s#server: https://[^:]*:6443#server: https://{{ kube_vip }}:6443#" /etc/kubernetes/kubelet.conf
              systemctl restart kubelet
            else
              echo "WARNING: /etc/kubernetes/kubelet.conf not found. Kubelet may not be initialized yet."
            fi
            set -e
            echo "Updating the arguments for kube-controller-manager"
            MANIFEST="/etc/kubernetes/manifests/kube-controller-manager.yaml"
            BACKUP="/tmp/kube-controller-manager.yaml"

            ARGS=(
              "--node-monitor-period=5s"
              "--node-monitor-grace-period=40s"
              "--node-eviction-rate=1"
              "--secondary-node-eviction-rate=1"
              "--terminated-pod-gc-threshold=50"
            )

            echo "Backing up kube-controller-manager manifest..."
            cp -a "$MANIFEST" "$BACKUP"

            # -----------------------------------------
            # Update --controllers= argument
            # -----------------------------------------
            OLD="--controllers=*,bootstrapsigner,tokencleaner"
            NEW="--controllers=*,nodeipam,nodelifecycle,bootstrapsigner,tokencleaner"

            echo "Checking and updating controllers argument in: $BACKUP"

            # Detect ANY existing --controllers= line (with or without OLD)
            if grep -Fq -- "--controllers=" "$BACKUP"; then
              echo "Existing controllers line found. Updating..."
              # Replace entire existing controllers argument safely
              sed -i "s|.*--controllers=.*|    - $NEW|" "$BACKUP"
            else
              echo "No controllers line found. Adding new one..."
              # Insert after the kube-controller-manager entry
              sed -i "/- kube-controller-manager/a \ \ \ \ - $NEW" "$BACKUP"
            fi

            for ARG in "${ARGS[@]}"; do
              if grep -Fq -- "$ARG" "$BACKUP"; then
                echo "Already present: $ARG"
              else
                echo "Adding: $ARG"
                sed -i "/- kube-controller-manager/a \ \ \ \ - $ARG" "$BACKUP"
              fi
            done
            yes | cp -i  "$BACKUP" "$MANIFEST"


            echo "All arguments processed successfully."
            echo "kubelet will auto-restart kube-controller-manager within 30-60 seconds."

            echo "Waiting for Kubernetes API..."
            until kubectl get nodes >/dev/null 2>&1; do
              sleep 10
            done

            echo "Updating the kubelet arguments."
            sed -i 's/^shutdownGracePeriod:.*/shutdownGracePeriod: 30s/' /var/lib/kubelet/config.yaml
            sed -i 's/^shutdownGracePeriodCriticalPods:.*/shutdownGracePeriodCriticalPods: 10s/' /var/lib/kubelet/config.yaml

            #update the kubelet config.yaml
            CONFIG_FILE="/var/lib/kubelet/config.yaml"

            # Update or add the parameters
            sed -i 's|^nodeStatusUpdateFrequency:.*|nodeStatusUpdateFrequency: 10s|' $CONFIG_FILE
            sed -i 's|^nodeStatusReportFrequency:.*|nodeStatusReportFrequency: 60s|' $CONFIG_FILE
            sed -i 's|^syncFrequency:.*|syncFrequency: 60s|' $CONFIG_FILE

            # If a key is missing, append it
            grep -q "^nodeStatusUpdateFrequency:" $CONFIG_FILE || echo "nodeStatusUpdateFrequency: 10s" >> $CONFIG_FILE
            grep -q "^nodeStatusReportFrequency:" $CONFIG_FILE || echo "nodeStatusReportFrequency: 60s" >> $CONFIG_FILE
            grep -q "^syncFrequency:" $CONFIG_FILE || echo "syncFrequency: 60s" >> $CONFIG_FILE

            systemctl daemon-reload
            systemctl restart kubelet

            kubectl -n kube-system wait pod/kube-controller-manager-{% raw %}{{ ds.meta_data.instance_data.local_ipv4 }}{% endraw %} --for=condition=Ready --timeout=300s
            systemctl restart nfs-client.target
            systemctl restart rpcbind
              # Mark initialization complete so all of above is skipped on reboot!
            touch "$MARKER"
            echo "Cloud-Init has completed successfully."
          else
            # SUBSEQUENT BOOT - SKIP JOIN
            echo "service_kube_control_plane_x86_64 is already part of cluster."
            echo "Cluster already initialized. Performing node reboot procedures."
            # CRI and kubelet already enabled above
            # You can log health status etc if you wish:
            mkdir -p $HOME/.kube /root/.kube
            cp -f /etc/kubernetes/admin.conf $HOME/.kube/config
            chown $(id -u):$(id -g) $HOME/.kube/config
            yes | cp -i /etc/kubernetes/admin.conf /root/.kube/config
            kubectl get nodes -o wide || echo "Cluster not yet fully up"
            kubectl get pods --all-namespaces -o wide || echo "Pods may not be ready yet"
            echo "Rollout and Restart coredns"
            kubectl rollout restart deployment coredns -n kube-system
            echo "Waiting for coredns pods to appear.."
            sleep 30
            kubectl wait --for=condition=Ready pod -l k8s-app=kube-dns -n kube-system --timeout=300s
            # Wait for all pods in all namespaces to be ready (status=Running or Completed)
            echo "Waiting for all pods to be Ready (Running/Completed)..."
            while true; do
              not_ready=$(kubectl get pods --all-namespaces --no-headers 2>/dev/null | awk '{ print $4 }' | grep -vE '^(Running|Completed)$' | wc -l)
              if [ "${not_ready}" -eq 0 ]; then
                echo "All pods are Running or Completed."
                break
              else
                echo "$not_ready pods not yet ready, waiting 5s ..."
                sleep 5
              fi
            done

            echo "Listing all Kubernetes nodes:"
            kubectl get nodes -o wide
            echo "Listing all Kubernetes pods in all namespaces:"
            kubectl get pods --all-namespaces -o wide
            echo "Cloud-Init finished successfully after the reboot."
          fi
