#  Copyright 2025 Dell Inc. or its subsidiaries. All Rights Reserved.
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.

apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-config
  namespace: telemetry
data:
  server.properties: |
    ###############################
    # Apache Kafka : KRaft mode
    ###############################
    process.roles=broker,controller
    node.id=__NODE_ID__
    controller.listener.names=CONTROLLER
    controller.quorum.voters=0@kafka-0.kafka-headless.telemetry.svc.cluster.local:9093,1@kafka-1.kafka-headless.telemetry.svc.cluster.local:9093,2@kafka-2.kafka-headless.telemetry.svc.cluster.local:9093

    log.dirs=/opt/kafka/data

    ###############################
    # Listeners
    ###############################
    listeners=INTERNAL://:9092,CONTROLLER://:9093
    advertised.listeners=INTERNAL://__POD_NAME__.kafka-headless.telemetry.svc.cluster.local:9092
    listener.security.protocol.map=CONTROLLER:SSL,INTERNAL:SSL
    inter.broker.listener.name=INTERNAL

    ###############################
    # TLS / SSL
    ###############################
    ssl.keystore.type=PEM
    ssl.keystore.location=/opt/kafka/tls/kafka.keystore.combined.pem
    ssl.key.location=
    ssl.truststore.type=PEM
    ssl.truststore.location=/opt/kafka/tls/kafka.truststore.pem
    ssl.client.auth=none

    ###############################
    # Topic / log defaults
    ###############################
    num.partitions={{ hostvars['localhost']['kafka_configurations']['topic_partitions'] }}
    offsets.topic.replication.factor=1
    transaction.state.log.replication.factor=1
    transaction.state.log.min.isr=1
    log.retention.hours={{ hostvars['localhost']['kafka_configurations']['log_retention_hours'] }}
    log.segment.bytes={{ hostvars['localhost']['kafka_configurations']['log_segment_bytes'] }}
    log.retention.bytes={{ hostvars['localhost']['kafka_configurations']['log_retention_bytes'] }}
    log.retention.check.interval.ms=300000
---
# Kafka KRaft Cluster ID Secret
apiVersion: v1
kind: Secret
metadata:
  name: "{{ kafka.cluster_id }}"
  namespace: "{{ telemetry_namespace }}"
type: Opaque
stringData:
  cluster-id: "{{ cluster_id.stdout }}"
---
# Kafka Headless Service
apiVersion: v1
kind: Service
metadata:
  name: "{{ kafka.service_name }}"
  namespace: "{{ telemetry_namespace }}"
  labels:
    app: "{{ kafka.app_name }}"
spec:
  clusterIP: None
  selector:
    app: "{{ kafka.app_name }}"
  ports:
    - name: kafka
      port: 9092
---
# Kafka LoadBalancer Service
apiVersion: v1
kind: Service
metadata:
  name: "{{ kafka.lb_service_name }}"
  namespace: "{{ telemetry_namespace }}"
  labels:
    app: "{{ kafka.app_name }}"
spec:
  type: LoadBalancer
  selector:
    app: "{{ kafka.app_name }}"
  ports:
    - name: kafka
      port: 9092
---
# Kafka TLS Secret
apiVersion: v1
kind: Secret
metadata:
  name: "{{ kafka_secrets.name }}"
  namespace: "{{ telemetry_namespace }}"
type: Opaque
data:
  kafka.keystore.pem: "{{ lookup('file', kafka_secrets.cert_file) | b64encode }}"
  kafka.keystore.key: "{{ lookup('file', kafka_secrets.cert_key) | b64encode }}"
  kafka.truststore.pem: "{{ lookup('file', kafka_secrets.cacert_file) | b64encode }}"
  kafka.keystore.combined.pem: "{{ lookup('file', kafka_secrets.combined_pem) | b64encode }}"
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: {{ telemetry_namespace }}
spec:
  serviceName: {{ kafka.service_name }}
  replicas: 1
  selector:
    matchLabels:
      app: {{ kafka.app_name }}
  template:
    metadata:
      labels:
        app: {{ kafka.app_name }}
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - {{ kafka.app_name }}
                topologyKey: "kubernetes.io/hostname"
      terminationGracePeriodSeconds: 3
      tolerations:
        - key: node.kubernetes.io/not-ready
          operator: Exists
          effect: NoExecute
          tolerationSeconds: 5
        - key: node.kubernetes.io/unreachable
          operator: Exists
          effect: NoExecute
          tolerationSeconds: 5
      containers:
      - name: {{ kafka.container_name }}
        image: {{ kafka.image }}
        imagePullPolicy: IfNotPresent
        ports:
          - containerPort: 9092
            name: internal
          - containerPort: 9093
            name: controller
        lifecycle:
          postStart:
            exec:
              command:
                - /bin/sh
                - -c
                - |
                  echo "Creating client-ssl.properties..."
                  cat <<EOF > /opt/kafka/config/client-ssl.properties
                  security.protocol=SSL
                  ssl.truststore.type=PEM
                  ssl.truststore.location=/opt/kafka/tls/kafka.truststore.pem
                  ssl.keystore.type=PEM
                  ssl.keystore.location=/opt/kafka/tls/kafka.keystore.combined.pem
                  ssl.key.location=/opt/kafka/tls/kafka.key.pem
                  EOF
        command: ["/bin/bash", "-c"]
        args:
          - |
            set -e
            echo "Starting Kafka in KRaft mode"

            NODE_ID=$(echo ${POD_NAME} | grep -o '[0-9]*$')
            echo "Using node.id=${NODE_ID}"

            mkdir -p /opt/kafka/config-runtime
            cp /opt/kafka/base-config/server.properties /opt/kafka/config-runtime/server.properties

            # Replace placeholders
            sed -i "s/__NODE_ID__/${NODE_ID}/" /opt/kafka/config-runtime/server.properties
            sed -i "s/__POD_NAME__/${POD_NAME}/" /opt/kafka/config-runtime/server.properties

            echo "Formatting storage if needed..."
            if [ ! -f "/opt/kafka/data/meta.properties" ]; then
              /opt/kafka/bin/kafka-storage.sh format --ignore-formatted --cluster-id=${KAFKA_KRAFT_CLUSTER_ID} --config /opt/kafka/config-runtime/server.properties
            fi

            echo "Starting Kafka..."
            exec /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config-runtime/server.properties
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: KAFKA_KRAFT_CLUSTER_ID
          valueFrom:
            secretKeyRef:
              name: kafka-cluster-id
              key: cluster-id
        volumeMounts:
          - name: kafka-data
            mountPath: /opt/kafka/data
          - name: kafka-config
            mountPath: /opt/kafka/base-config
          - name: kafka-tls
            mountPath: /opt/kafka/tls
            readOnly: true
      volumes:
        - name: kafka-config
          configMap:
            name: kafka-config
        - name: kafka-tls
          secret:
            secretName: {{ kafka_secrets.name }}
            defaultMode: 420
  volumeClaimTemplates:
    - metadata:
        name: kafka-data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: "{{ hostvars['localhost']['kafka_configurations']['persistence_size'] }}"
        storageClassName: {{ storage_class_name }}
