# Copyright 2025 Dell Inc. or its subsidiaries. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: Include variable file omnia_config.yml
  ansible.builtin.include_vars: "{{ input_project_dir }}/omnia_config.yml"

- name: Include storage vars
  ansible.builtin.include_vars: "{{ input_project_dir }}/storage_config.yml"

- name: Load slurm_custom.json for x86_64
  ansible.builtin.include_vars:
    file: "{{ input_project_dir }}/config/x86_64/rhel/{{ hostvars['localhost']['cluster_os_version'] }}/slurm_custom.json"
    name: slurm_custom_x86_64
  failed_when: false

- name: Load slurm_custom.json for aarch64
  ansible.builtin.include_vars:
    file: "{{ input_project_dir }}/config/aarch64/rhel/{{ hostvars['localhost']['cluster_os_version'] }}/slurm_custom.json"
    name: slurm_custom_aarch64
  failed_when: false

- name: Extract CUDA runfile name for x86_64 from slurm_custom.json
  ansible.builtin.set_fact:
    cuda_runfile_x86_64: "{{ (slurm_custom_x86_64.slurm_node.cluster | selectattr('package', 'equalto', 'cuda-run') | first).url | basename }}"
  when:
    - slurm_custom_x86_64 is defined
    - slurm_custom_x86_64.slurm_node is defined
    - slurm_custom_x86_64.slurm_node.cluster | selectattr('package', 'equalto', 'cuda-run') | list | length > 0

- name: Extract CUDA runfile name for aarch64 from slurm_custom.json
  ansible.builtin.set_fact:
    cuda_runfile_aarch64: "{{ (slurm_custom_aarch64.slurm_node.cluster | selectattr('package', 'equalto', 'cuda-run') | first).url | basename }}"
  when:
    - slurm_custom_aarch64 is defined
    - slurm_custom_aarch64.slurm_node is defined
    - slurm_custom_aarch64.slurm_node.cluster | selectattr('package', 'equalto', 'cuda-run') | list | length > 0

- name: Set facts for slurm
  ansible.builtin.set_fact:
    nfs_storage_name: "{{ slurm_cluster[0].nfs_storage_name }}"

- name: Read the slurm mount point
  ansible.builtin.set_fact:
    share_path: "{{ (nfs_client_params | selectattr('nfs_name', 'equalto', nfs_storage_name) | first).client_share_path }}"
    nfs_server_ip: "{{ (nfs_client_params | selectattr('nfs_name', 'equalto', nfs_storage_name) | first).server_ip }}"
    nfs_server_path: "{{ (nfs_client_params | selectattr('nfs_name', 'equalto', nfs_storage_name) | first).server_share_path }}"

- name: Set facts for slurm
  ansible.builtin.set_fact:
    cluster_name: "{{ slurm_cluster[0].cluster_name }}"
    configs_input: "{{ slurm_cluster[0].config_sources | default({}) | dict2items | rejectattr('value', 'falsy') | list | items2dict }}"
    slurm_config_path: "{{ share_path }}/{{ slurm_dir_name }}"
    controller_trackfile_path: "{{ share_path }}/ctld_track"

- name: Configure openldap if supported
  ansible.builtin.include_tasks: openldap_config.yml
  when: hostvars['localhost']['openldap_support']

- name: Set facts for slurm
  ansible.builtin.set_fact:
    share_prefix: "{{ slurm_config_path }}"
  when: conf_in_nfs

- name: Clear the share directory
  ansible.builtin.file:
    path: "{{ slurm_config_path }}"
    state: absent
  when: clear_slurm_files

- name: Create the slurm directory in share
  ansible.builtin.file:
    path: "{{ slurm_config_path }}"
    state: directory
    owner: root
    group: root
    mode: "{{ common_mode }}"

# This directory is created to store the controller track file in NFS
# The track file is generated only after the Slurm controller has been fully configured in a fresh deployment
- name: Create directory for controller init track file in share
  ansible.builtin.file:
    path: "{{ controller_trackfile_path }}"
    state: directory
    owner: root
    group: root
    mode: "{{ common_mode }}"

- name: Create the slurm ctld directory on share
  ansible.builtin.file:
    path: "{{ slurm_config_path }}/{{ item[0] }}{{ item[1] }}"
    state: directory
    owner: root
    group: root
    mode: "{{ common_mode }}"
  when: ctld_list
  loop: "{{ ctld_list | product(ctld_dir) }}"

- name: Create the slurm cmpt directory on share
  ansible.builtin.file:
    path: "{{ slurm_config_path }}/{{ item[0] }}{{ item[1] }}"
    state: directory
    owner: root
    group: root
    mode: "{{ common_mode }}"
  when: cmpt_list or login_list or compiler_login_list
  loop: "{{ (cmpt_list + login_list + compiler_login_list) | product(cmpt_dir) }}"

- name: Create the cert directory on share
  ansible.builtin.file:
    path: "{{ slurm_config_path }}/cert"
    state: directory
    owner: root
    group: root
    mode: "{{ common_mode }}"

- name: Copy pulp webserver certificate to client_share_path
  ansible.builtin.copy:
    src: "{{ pulp_webserver_cert_path }}"
    dest: "{{ slurm_config_path }}/cert"
    mode: "{{ file_mode }}"
  become: true

# Move to packages directory moving forward
- name: Create the cuda directory on share
  ansible.builtin.file:
    path: "{{ slurm_config_path }}/cuda"
    state: directory
    owner: root
    group: root
    mode: "{{ common_mode }}"

- name: Create x86_64 package base directory
  ansible.builtin.file:
    path: "{{ packages_base_dir_x86_64 }}"
    state: directory
    mode: '{{ common_mode }}'

- name: Create aarch64 package base directory
  ansible.builtin.file:
    path: "{{ packages_base_dir_aarch64 }}"
    state: directory
    mode: '{{ common_mode }}'

- name: Create x86_64 package layout directories
  ansible.builtin.file:
    path: "{{ packages_base_dir_x86_64 }}/{{ item }}"
    state: directory
    mode: '{{ common_mode }}'
  loop: "{{ packages_layout_x86_64 }}"

- name: Create aarch64 package layout directories
  ansible.builtin.file:
    path: "{{ packages_base_dir_aarch64 }}/{{ item }}"
    state: directory
    mode: '{{ common_mode }}'
  loop: "{{ packages_layout_aarch64 }}"

- name: Print copy paths for x86_64
  ansible.builtin.debug:
    msg: "{{ print_copy_msg }}"
  loop: "{{ offline_path_x86_64 | default([]) }}"

- name: Print copy paths for aarch64
  ansible.builtin.debug:
    msg: "{{ print_copy_msg }}"
  loop: "{{ offline_path_aarch64 | default([]) }}"

- name: Check x86_64 offline package sources
  ansible.builtin.stat:
    path: "{{ item.source_path }}"
  loop: "{{ offline_path_x86_64 | default([]) }}"
  register: x86_64_offline_pkg_sources

- name: Check aarch64 offline package sources
  ansible.builtin.stat:
    path: "{{ item.source_path }}"
  loop: "{{ offline_path_aarch64 | default([]) }}"
  register: aarch64_offline_pkg_sources

- name: Copy x86_64 offline packages
  ansible.builtin.copy:
    src: "{{ item.item.source_path }}/"
    dest: "{{ item.item.dest_path }}/"
    remote_src: true
    mode: preserve
  loop: "{{ x86_64_offline_pkg_sources.results | default([]) }}"
  when:
    - item.stat.exists
    - item.item.source_path | length > 0
    - item.item.dest_path | length > 0

- name: Copy aarch64 offline packages
  ansible.builtin.copy:
    src: "{{ item.item.source_path }}/"
    dest: "{{ item.item.dest_path }}/"
    remote_src: true
    mode: preserve
  loop: "{{ aarch64_offline_pkg_sources.results | default([]) }}"
  when:
    - item.stat.exists
    - item.item.source_path | length > 0
    - item.item.dest_path | length > 0

- name: Create the runfile directory on share
  ansible.builtin.file:
    path: "{{ slurm_config_path }}/runfile"
    state: directory
    owner: root
    group: root
    mode: "{{ common_mode }}"

- name: Set NFS info fact
  ansible.builtin.set_fact:
    oim_shared_path: "{{ hostvars['localhost']['oim_shared_path'] }}"

- name: Check if source directory exists
  ansible.builtin.stat:
    path: "{{ oim_shared_path }}/omnia/offline_repo/cluster/x86_64/rhel/10.0/iso/cuda-run/"
  register: src_dir_check_x86_64

- name: Check if source directory exists
  ansible.builtin.stat:
    path: "{{ oim_shared_path }}/omnia/offline_repo/cluster/aarch64/rhel/10.0/iso/cuda-run/"
  register: src_dir_check_aarch64

- name: Copy cuda run file using copy module for aarch64
  ansible.builtin.copy:
    src: "{{ oim_shared_path }}/omnia/offline_repo/cluster/aarch64/rhel/10.0/iso/cuda-run/"
    dest: "{{ slurm_config_path }}/runfile/"
    mode: '0755'
    owner: root
    group: root
    directory_mode: '0755'
    remote_src: true
  when: src_dir_check_aarch64.stat.exists and src_dir_check_aarch64.stat.isdir

- name: Copy cuda run file using copy module for x86_64
  ansible.builtin.copy:
    src: "{{ oim_shared_path }}/omnia/offline_repo/cluster/x86_64/rhel/10.0/iso/cuda-run/"
    dest: "{{ slurm_config_path }}/runfile/"
    mode: '0755'
    owner: root
    group: root
    directory_mode: '0755'
    remote_src: true
  when: src_dir_check_x86_64.stat.exists and src_dir_check_x86_64.stat.isdir

- name: Check if munge key exists top level
  ansible.builtin.stat:
    path: "{{ slurm_config_path }}/munge.key"
  register: munge_present

- name: Ensure munge key is generated
  ansible.builtin.shell: "{{ munge_key_cmd }} > {{ slurm_config_path }}/munge.key"
  when: not munge_present.stat.exists
  register: munge_gen
  changed_when: munge_gen.rc == 0

- name: Distribute the munge key
  ansible.builtin.copy:
    src: "{{ slurm_config_path }}/munge.key"
    dest: "{{ slurm_config_path }}/{{ item }}/etc/munge/munge.key"
    mode: "{{ common_mode }}"
    remote_src: true
  loop: "{{ (ctld_list | default([])) +
            (cmpt_list | default([])) +
            (compiler_login_list | default([])) +
            (login_list | default([])) }}"

- name: Slurm path ops
  ansible.builtin.set_fact:
    conf_path_items: "{{ conf_path_items | default({}) | combine({item.key: item.value}) }}"
  when: item.value is string
  loop: "{{ configs_input | dict2items }}"

- name: Slurm dict ops
  ansible.builtin.set_fact:
    conf_dict_items: "{{ conf_dict_items | default({}) | combine({item.key: item.value}) }}"
  when: item.value is mapping
  loop: "{{ configs_input | dict2items }}"

- name: Slurm dict ops
  ansible.builtin.set_fact:
    apply_config: >-
      {{ apply_config | default({})
        | combine({
            item: (
              (__default_config[item] | default({}))
              | combine(conf_dict_items[item] | default({}))
            )
          })
      }}
  loop: "{{ conf_files }}"

- name: Read NodeName parameters
  ansible.builtin.include_tasks: read_node_idrac.yml
  when: cmpt_list
  loop: "{{ cmpt_list }}"

- name: Copy conf file if provided
  ansible.builtin.copy:
    src: "{{ conf_path_items.get(item.1) }}"
    dest: "{{ slurm_config_path }}/{{ item.0 }}/etc/slurm/{{ item.1 }}.conf"
    mode: "{{ conf_file_mode }}"
    remote_src: "{{ copy_from_oim }}"
  when: ctld_list
  loop: "{{ ctld_list | product(conf_path_items.keys() | default([])) }}"

- name: Add gpu parameters to slurm conf
  ansible.builtin.set_fact:
    apply_config: "{{ apply_config | default({}) | combine({'slurm': (apply_config['slurm'] | combine(gpu_slurm_conf))}) }}"
  when: gpu_params is defined and gpu_params

- name: Verify slurm conf keys only
  ansible.builtin.assert:
    that:
      - (apply_config[item].keys() | list) | difference(__conf_keys[item]) | length == 0
    fail_msg: "The following {{ item }} config keys are invalid: {{ apply_config[item].keys() | list | difference(__conf_keys[item]) | join(', ') }}"
  when: apply_config[item] and __conf_keys[item]
  loop: "{{ conf_files }}"

- name: Slurm dict ops
  ansible.builtin.set_fact:
    slurm_conf_dict: "{{ apply_config['slurm'] }}"

- name: Create all .conf for ctld only
  ansible.builtin.template:
    src: "{{ item.1 }}.conf.j2"
    dest: "{{ slurm_config_path }}/{{ item.0 }}/etc/slurm/{{ item.1 }}.conf"
    owner: "{{ root_user }}"
    group: "{{ root_group }}"
    mode: "{{ conf_file_mode }}"
  when: ctld_list
  loop: "{{ ctld_list | product(conf_files | difference(conf_path_items.keys() | default([]))) }}"

- name: Create mariadb cnf
  ansible.builtin.template:
    src: "mariadb-server.cnf.j2"
    dest: "{{ slurm_config_path }}/{{ item }}/etc/my.cnf.d/mariadb-server.cnf"
    owner: "{{ root_user }}"
    group: "{{ root_group }}"
    mode: "{{ conf_file_mode }}"
  when: ctld_list
  loop: "{{ ctld_list }}"

- name: Generate slurmd opts for Configless
  ansible.builtin.set_fact:
    conf_server: "--conf-server {{ ctld_list | map('regex_replace', '$', ':' ~ (apply_config['slurm']['SlurmctldPort'] | string)) | join(',') }}"

- name: Create epilog.sh and slurmd.service
  ansible.builtin.template:
    src: "{{ item.1 }}.j2"
    dest: "{{ slurm_config_path }}/{{ item.0 }}/etc/slurm/epilog.d/{{ item.1 }}"
    owner: "{{ root_user }}"
    group: "{{ root_group }}"
    mode: "{{ conf_file_mode }}"
  when: cmpt_list
  loop: "{{ cmpt_list | product(['logout_user.sh', 'slurmd.service']) }}"

- name: Create slurmd.service in login and login_compiler
  ansible.builtin.template:
    src: "{{ item.1 }}.j2"
    dest: "{{ slurm_config_path }}/{{ item.0 }}/etc/slurm/epilog.d/{{ item.1 }}"
    owner: "{{ root_user }}"
    group: "{{ root_group }}"
    mode: "{{ conf_file_mode }}"
  when: login_list or compiler_login_list
  loop: "{{ (login_list + compiler_login_list) | product(['slurmd.service']) }}"

- name: Get the slurm NFS path
  ansible.builtin.debug:
    msg: "The slurm NFS path is {{ share_path }}/slurm"

- name: NFS path for cloud init
  ansible.builtin.set_fact:
    cloud_init_nfs_path: "{{ nfs_server_ip }}:{{ nfs_server_path }}/slurm"

- name: NFS path for controller trackfile
  ansible.builtin.set_fact:
    trackfile_nfs_path: "{{ nfs_server_ip }}:{{ nfs_server_path }}/ctld_track"

- name: NFS path for cloud init
  ansible.builtin.set_fact:
    cloud_init_nfs_path_openldap: "{{ nfs_server_ip }}:{{ nfs_server_path }}/openldap"
  when: hostvars['localhost']['openldap_support']

# This will be mounted for ucx, openmpi and ldms configurations on slurm nodes
- name: NFS path for ucx, openmpi and ldms cloud init
  ansible.builtin.set_fact:
    cloud_init_slurm_nfs_path: "{{ nfs_server_ip }}:{{ nfs_server_path }}"
    client_mount_path: "{{ share_path }}"

- name: Ensure SSH key directory exists on Slurm share
  ansible.builtin.file:
    path: "{{ slurm_config_path }}/ssh"
    state: directory
    owner: root
    group: root
    mode: '0700'

- name: Copy OIM private key to Slurm share for node-to-node SSH
  ansible.builtin.copy:
    src: "{{ ssh_private_key_path }}"
    dest: "{{ slurm_config_path }}/ssh/oim_rsa"
    owner: root
    group: root
    mode: '0600'
